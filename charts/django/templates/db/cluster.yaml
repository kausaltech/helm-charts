{{- if .Values.db.cluster.create -}}
{{- $pgcluster := .Values.db.cluster -}}
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: {{ include "django.dbClusterName" . }}
spec:
  instances: {{ $pgcluster.instances }}
  {{- if .Values.db.postgis }}
  imageName: ghcr.io/cloudnative-pg/postgis:{{ $pgcluster.version }}
  {{- else }}
  imageName: ghcr.io/cloudnative-pg/postgresql:{{ $pgcluster.version }}
  {{- end }}
  {{- with $pgcluster.affinity }}
  affinity:
    {{- toYaml . | nindent 4 }}
  {{- end }}
  bootstrap:
    initdb:
      database: {{ .Values.db.database }}
      owner: {{ .Values.db.user }}
      dataChecksums: {{ $pgcluster.dataChecksums }}
      {{- if .Values.db.postgis }}
      postInitTemplateSQL:
        - CREATE EXTENSION postgis;
      {{- end }}
  # Example of rolling update strategy:
  # - unsupervised: automated update of the primary once all
  #                 replicas have been upgraded (default)
  # - supervised: requires manual supervision to perform
  #               the switchover of the primary
  primaryUpdateStrategy: unsupervised
  {{- if $pgcluster.enablePodMonitor }}
  monitoring:
    enablePodMonitor: true
  {{- end }}
  {{- if $pgcluster.parameters }}
  postgresql:
    parameters:
      {{- toYaml $pgcluster.parameters | nindent 6 }}
  {{- end }}
  storage:
    size: {{ $pgcluster.size }}
    {{- if $pgcluster.storageClass }}
    storageClass: {{ $pgcluster.storageClass }}
    {{- end -}}
  {{- if $pgcluster.backup.enabled }}
  {{- $pgbackup := $pgcluster.backup }}
  backup:
    target: prefer-standby
    retentionPolicy: "{{ $pgbackup.retentionPolicy }}"
    barmanObjectStore:
      destinationPath: {{ $pgbackup.destinationPath }}
      endpointURL: {{ $pgbackup.endpointUrl }}
      s3Credentials:
        accessKeyId:
          name: {{ $pgbackup.s3Secret.name | required "Value db.cluster.backup.s3Secret.name required" }}
          key: {{ $pgbackup.s3Secret.accessKeyName }}
        secretAccessKey:
          name: {{ $pgbackup.s3Secret.name }}
          key: {{ $pgbackup.s3Secret.secretAccessKeyName }}
  {{- end }}
  {{/* TODO: How to enable this safely? */}}
  {{- if .Values.db.cluster.bootstrapRecovery.enabled }}
  bootstrap:
    recovery:
      source: cluster-bootstrap-recovery
  externalClusters:
    - name: cluster-bootstrap-recovery
      # Use same storage location as for backups for now. Note that enabling backups and bootstrapRecovery
      # at the same time will probably result in an error. From the docs:
      # You should not re-use the exact same barmanObjectStore configuration for different clusters. There could be
      # cases where the existing information in the storage buckets could be overwritten by the new cluster.
      # The operator includes a safety check to ensure a cluster will not overwrite a storage bucket that contained
      # information. A cluster that would overwrite existing storage will remain in state Setting up primary with
      # Pods in an Error state. The pod logs will show: ERROR: WAL archive check failed for server recoveredCluster:
      # Expected empty archive
      barmanObjectStore:
        destinationPath: {{ .Values.db.cluster.backup.destinationPath }}
        endpointURL: {{ .Values.db.cluster.backup.endpointUrl }}
        serverName: {{ include "django.dbClusterName" . }}
        s3Credentials:
          accessKeyId:
            name: {{ include "django.dbBackupS3SecretName" . }}
            key: AWS_ACCESS_KEY_ID
          secretAccessKey:
            name: {{ include "django.dbBackupS3SecretName" . }}
            key: AWS_SECRET_ACCESS_KEY
      wal:
        maxParallel: 8
  {{- end }}
{{- end -}}
